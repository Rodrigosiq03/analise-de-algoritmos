# Cola Definitiva de **NotaÃ§Ã£o AssintÃ³tica**

> **Objetivo** â€“ Ser o guia rÃ¡pido (e completo) para vocÃª bater o olho em uma expressÃ£o ou em um trecho de cÃ³digo e **cravar** as respostas de *Bigâ€‘O*, *Bigâ€‘Omega* e *Bigâ€‘Theta* na prova.

---

## Ãndice

1. [Por que precisamos de notaÃ§Ã£o assintÃ³tica?](#por-que)
2. [DefiniÃ§Ãµes formais â€“ O, Î© e Î˜](#definicoes)
3. [Regra de ouro para funÃ§Ãµes matemÃ¡ticas](#regra-funcoes)
4. [Passoâ€‘aâ€‘passo para cÃ³digos (loops, condicionais, recursÃ£o)](#passo-codigo)
5. [DiferenÃ§a prÃ¡tica entre ](#o-vs-omega)[**O(n)**](#o-vs-omega)[ e ](#o-vs-omega)[**Î©(n)**](#o-vs-omega)
6. [Exemplos clÃ¡ssicos & pegadinhas da prova](#exemplos)
   - 6.1 5nÂ²Â +Â 3nÂ +Â 7 Ã— nÂ²
   - 6.2 Programa **ProcessaVetor** (Java)
   - 6.3 GrÃ¡fico com câ‚Â·g(n) e câ‚‚Â·g(n)
7. [Tabela de consulta rÃ¡pida](#tabela)
8. [Checklist final antes de marcar a alternativa](#checklist)

---



## 1. Por que precisamos de notaÃ§Ã£o assintÃ³tica?

Medir tempo real de execuÃ§Ã£o Ã© inviÃ¡vel para todas as entradas; queremos **comparar algoritmos independentemente de hardware**. Usamos funÃ§Ãµes *f(n)* (tempo, nÃºmero de operaÃ§Ãµes) em funÃ§Ã£o do tamanho *n* da entrada e descrevemos o **comportamento quando n cresce sem limite**.



- **O (Bigâ€‘O)** â€‘ limite **superior** (teto): *f(n)* cresce **no mÃ¡ximo** tÃ£o rÃ¡pido quanto *g(n)*.
- **Î© (Bigâ€‘Omega)** â€‘ limite **inferior** (piso): *f(n)* cresce **pelo menos** tÃ£o rÃ¡pido quanto *g(n)*.
- **Î˜ (Bigâ€‘Theta)** â€‘ quando teto = piso (corredor estreito): *f(n)* cresce **na mesma ordem** de *g(n)*.

---



## 2. DefiniÃ§Ãµes formais

| SÃ­mbolo     | DefiniÃ§Ã£o matemÃ¡tica                                                               |
| ----------- | ---------------------------------------------------------------------------------- |
| **O(g(n))** | âˆƒ *c*>0, *nâ‚€* tal que 0Â â‰¤Â *f(n)*Â â‰¤Â *cÂ·g(n)* para todo *nÂ â‰¥Â nâ‚€*                     |
| **Î©(g(n))** | âˆƒ *c*>0, *nâ‚€* tal que 0Â â‰¤Â *cÂ·g(n)*Â â‰¤Â *f(n)* para todo *nÂ â‰¥Â nâ‚€*                     |
| **Î˜(g(n))** | âˆƒ *câ‚*, *câ‚‚*>0, *nâ‚€* tal que 0Â â‰¤Â *câ‚Â·g(n)*Â â‰¤Â *f(n)*Â â‰¤Â *câ‚‚Â·g(n)* para todo *nÂ â‰¥Â nâ‚€* |

ğŸ”‘ **TraduÃ§Ã£o para humanos**

- *O* â†’ â€œnÃ£o passa deâ€
- *Î©* â†’ â€œnÃ£o cai abaixo deâ€
- *Î˜* â†’ â€œfica preso entreâ€

---



## 3. Regra de ouro para funÃ§Ãµes matemÃ¡ticas

1. **Encontre o termo de maior crescimento** (maior expoente ou mais rÃ¡pido â€“ por ex., exponencial > polinomial > logarÃ­tmico > constante).
2. **Jogue fora constantes multiplicativas** (5nÂ² ~~â†’ nÂ²~~).
3. **Despreze termos menores** (*nÂ²* domina *n* e *log n*).\
   `7nÂ³ + 4n log n + 42  â‡’  Î˜(nÂ³)`
4. Se a funÃ§Ã£o for polinomial  *aâ‚–náµ + ... + aâ‚€*, entÃ£o:
   - O, Î© e Î˜ **coincidem** em *náµ*.

> **Atalho mental** âš¡ â€“ *â€œMaior potÃªncia ganha. Multiplicadores nÃ£o importam.â€*

---



## 4. Passoâ€‘aâ€‘passo para cÃ³digos

### 4.1 Fluxo sequencial

Somamos custos: `O(f) + O(g) = O(max(f,g))`\
Ex.: ler vetor *(n)* + somar *(n)* â‡’ `O(n)`.

### 4.2 Loops simples

```python
for i in range(n):
    ...          # O(1) interno
```

Custo = n Â· O(1) â‡’ **O(n)**.

### 4.3 Loops aninhados

```python
for i in range(n):
    for j in range(n):
        ...        # O(1)
```

Produto dos limites â‡’ **O(nÂ²)**.

### 4.4 Loop que reduz o problema

```python
while n > 1:
    n = n//2   # divide por 2
```

NÃºmero de iteraÃ§Ãµes â‰ˆ logâ‚‚ n â‡’ **O(log n)**.

### 4.5 RecursÃ£o tÃ­pica

- Merge Sort: `T(n)=2T(n/2)+O(n)` â†’ **O(n log n)**.
- Quick Sort pior caso: `T(n)=T(nâˆ’1)+O(n)` â†’ **O(nÂ²)**.

### 4.6 Pistas visuais (malÃ­cias)

| PadrÃ£o                                     | Complexidade   |
| ------------------------------------------ | -------------- |
| **Somar**/percorrer estrutura              | O(n)           |
| **Dois laÃ§os independentes** um apÃ³s outro | O(n)+O(n)=O(n) |
| **LaÃ§os encaixados** com mesmo limite      | O(nÂ²)          |
| **LaÃ§o que corta pela metade**             | O(log n)       |
| **RecursÃ£o tipo Ã¡rvore completa**          | O(n log n)     |

---



## 5. DiferenÃ§a prÃ¡tica entre `O(n)` e `Î©(n)`

- `O(n)` â€“ **garante um teto**: o algoritmo nunca serÃ¡ pior que linear (apÃ³s certo *n*).
- `Î©(n)` â€“ **garante um piso**: sempre gastarÃ¡ pelo menos tempo linear.

Quando **ambos** valem, temos `Î˜(n)` (bound apertado).\
**Exemplo:** varrer array para somar âœ `O(n)` + `Î©(n)` = `Î˜(n)`.

> ğŸ’¡ **Dica de prova:** Se vocÃª sÃ³ varre todos os elementos uma vez, sabe que nÃ£o Ã© melhor que linear (Î©(n)) nem pior (O(n)) â‡’ marque `Î˜(n)` se perguntarem.

---



## 6. Exemplos (baseados na sua prova)

### 6.1 FunÃ§Ãµes `f(n)=5nÂ²+3n+7` e `g(n)=nÂ²`

- **Passo 1**: termo dominante â†’ `nÂ²`.
- **ComparaÃ§Ã£o**:\
  `5nÂ²+3n+7  â‰¤ 5nÂ²+3nÂ²+7nÂ² = 15nÂ²` (para nâ‰¥1).\
  `5nÂ²+3n+7  â‰¥ 5nÂ²`.
- ExistirÃ£o câ‚=5, câ‚‚=15 e nâ‚€=1 tais que\
  `câ‚Â·g(n) â‰¤ f(n) â‰¤ câ‚‚Â·g(n)`.
- **ConclusÃ£o**: `f âˆˆ Î˜(g)`, logo tambÃ©m `O(g)` e `Î©(g)`.

### 6.2 CÃ³digo **ProcessaVetor** (Java mostrado no enunciado)

```java
int[] vetor = new int[args.length];             // O(n)
for (int i=0; i < args.length; i++) { ... }      // O(n)
int soma = 0;
for (int i=0; i < vetor.length; i++) { soma += vetor[i]; } // O(n)
int maximo = vetor[0];
for (int i=1; i < vetor.length; i++) { ... }     // O(n)
```

- Quatro passos lineares â‡’ **O(4n) = O(n)**.
- Precisa olhar todos os elementos â†’ **Î©(n)**.
- NÃ£o Ã© `Î˜(1)` de jeito nenhum (executa + cresce com n).

### 6.3 GrÃ¡fico com câ‚Â·g(n) e câ‚‚Â·g(n)

- Se *f(n)* oscila mas eventualmente fica entre as curvas verde (câ‚Â·g) e amarela (câ‚‚Â·g) depois de nâ‚€, entÃ£o podemos afirmar `f âˆˆ Î˜(g)` **mesmo que antes de nâ‚€ isso nÃ£o aconteÃ§a**.
- O grÃ¡fico da questÃ£o confundia ao destacar a regiÃ£o `0 â‰¤ n < nâ‚€`; lembreâ€‘se de que as definiÃ§Ãµes **comeÃ§am em nâ‚€** â€“ antes disso vale qualquer coisa.

---



## 7. Tabela de consulta rÃ¡pida

| PadrÃ£o de cÃ³digo / funÃ§Ã£o                 | O(n)      | Î©(n)        | Î˜(n)      |
| ----------------------------------------- | --------- | ----------- | --------- |
| Loop Ãºnico atÃ© n                          | âœ”         | âœ”           | âœ”         |
| Dois loops aninhados nÃ—n                  | âœ” (nÂ²)    | âœ” (nÂ²)      | âœ” (nÂ²)    |
| Busca binÃ¡ria                             | âœ” (log n) | âœ” (log n)   | âœ” (log n) |
| Soma constante de nÃºmeros                 | âœ” (1)     | âœ” (1)       | âœ” (1)     |
| Algoritmo que depende de pivÃ´ (QuickSort) | âœ” (nÂ²)    | âœ” (n log n) | âœ–         |

---



## 8. Checklist final âš™ï¸

1. **Identifique a maior operaÃ§Ã£o que repete**.
2. **Procure loops aninhados** â†’ multiplicaÃ§Ã£o de limites.
3. **ReduÃ§Ãµes pela metade** indicam `log n`.
4. Verifique se todo elemento Ã© visitado **obrigatoriamente** â†’ isto dÃ¡ Î©(n).
5. Se O = Î© â†’ marque Î˜.
6. Ignore **constantes e termos menores** â€“ nÃ£o perca tempo!

---

### Ãšltimo conselho â°

Treine fazer 10 exercÃ­cios cronometrando 1Â min por funÃ§Ã£o/cÃ³digo. Seu olho vai ficar automÃ¡tico.

Boa prova! ğŸ’ª

